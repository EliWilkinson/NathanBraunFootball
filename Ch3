'''
Pandas

Most information rich chapter in the book 
1) data from csv (comma separated values) file ---> DataFrame
2) access specific columns and rows
3) learn indexes in DataFrames
4) outputting DataFrames as csv files

Had to change variable to file path BEFORE importing os and pandas
  -successfully created a DataFrame

DataFrame.head() shows the first five rows of our data
  - ... shows some columns won't fit on screen
  - very useful as we go

#Working with subsets of DataFrames
  - getting one single column similar to a dicitonary
  - adp['name'].head()
  - technically a Series.. NOT a DataFrame
  -not important now, but will come up later
  -Don't forget:
  adp[['name', 'position', 'adp']].head()
  
  The extra pair of brackets is essential


Page 60/61
  -seems like changing argument to inplace= True to set our left most column would be easier,
  but the alternative would be worth revisiting one day

Main benefit of indexing is keeping things aligned

Lot of tests and boolean stuff so far
end page 68
Part 2

numPy is a more more raw math oriented python library

Pg 69
Flag means to make a column of booleans

= pg['pos'].apply(
  lambda x: x in [ ])

Missing values in pandas have the value: np.nan
np means mumPy library that pandas is built on

3.1.5 is tricky

Axis
  axis = 0 (aka columns)
  axis = 1 (aka rows)


Summary functions on Boolean Columns
  0 for False
  1 for True

The .any(axis=1) or .all(axis=1) are good ways to make conditions

IMPORTANT:
  should play around with:
    pd. tab completing- high level Pandas funcitons
    pd.Series tab - operations on single columns
    pd.DataFrame tab -specific methods on DataFrames

loc
  - can pass a second argument
  adp.loc[my_player_names, 'name']

boolean indexing is mroe common

Can be cumbersome to use the name of your DataFrame, however it is common practice "you'll get used to it"

A common way to filter data is by removing duplicates

pg 81:
the loc method is flexible and can do everything you need... but:
querying is a less verbose way of only filtering

Reminder: pg is a separate DataFrame from adp

Granularity

pg 87- multilevel indexing is doable, narrator avoids it for the most part

Stacking and Unstacking- doesn't come up too often
- moving data from columns to rows or vice versa

pt 5 Exercise notes
3.5.1: generally, data can only go from more to less granular, meaning some information is going to be lost in the process

Merging
Combining dataFrames, side by side. like a bookshelf
Can be done vertically too

1)What columns are you joining?

Merging is precise
- lots of time is devoted to making sure names and such matchup. Like Odell Beckham vs OBJ or Odell Beckham Jr. or JR.

2)Are you doing 1 to 1, 1 to many,  or many to many join?
1:1, 1:M, M:M

1:M comes up a lot when data is efficiently stored, M:M is very rare to see

validate keyword is a good habit to get into:
pd.merge(combined, player, validate= '1:1')

3) What are you doing with unmatched observations?
Pandas automatically keeps observations in both tables

tricky when a bunch of players only show having one of either rushing, or receiving stats
'''
